{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import utils\n",
    "from nets.NetMLPLowRank import NetMLPLowRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "batch_size_test = 1000\n",
    "\n",
    "train_loader, test_loader = utils.build_dataset(dataset='MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 200 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.361188\n",
      "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 0.422387\n",
      "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 0.176567\n",
      "\n",
      "Test set: Average loss: -6.3668, Accuracy: 9245/10000 (92%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.196499\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.152591\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.160524\n",
      "\n",
      "Test set: Average loss: -7.4443, Accuracy: 9392/10000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.186170\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.201154\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.247151\n",
      "\n",
      "Test set: Average loss: -7.8705, Accuracy: 9432/10000 (94%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.100479\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.317804\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.111834\n",
      "\n",
      "Test set: Average loss: -8.1655, Accuracy: 9529/10000 (95%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.072163\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.107400\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.110389\n",
      "\n",
      "Test set: Average loss: -8.5807, Accuracy: 9532/10000 (95%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.085312\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.262971\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.271603\n",
      "\n",
      "Test set: Average loss: -9.0958, Accuracy: 9530/10000 (95%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.053293\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.158440\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.061059\n",
      "\n",
      "Test set: Average loss: -8.8026, Accuracy: 9374/10000 (94%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.162062\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.073478\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.222886\n",
      "\n",
      "Test set: Average loss: -9.3748, Accuracy: 9482/10000 (95%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.139204\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.104272\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.114832\n",
      "\n",
      "Test set: Average loss: -9.7314, Accuracy: 9544/10000 (95%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.136902\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.183733\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.178219\n",
      "\n",
      "Test set: Average loss: -9.6054, Accuracy: 9551/10000 (96%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.026970\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.051156\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.158363\n",
      "\n",
      "Test set: Average loss: -9.5599, Accuracy: 9518/10000 (95%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.181510\n",
      "Train Epoch: 11 [20000/60000 (33%)]\tLoss: 0.139381\n",
      "Train Epoch: 11 [40000/60000 (67%)]\tLoss: 0.025671\n",
      "\n",
      "Test set: Average loss: -9.8725, Accuracy: 9567/10000 (96%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.028976\n",
      "Train Epoch: 12 [20000/60000 (33%)]\tLoss: 0.111973\n",
      "Train Epoch: 12 [40000/60000 (67%)]\tLoss: 0.092873\n",
      "\n",
      "Test set: Average loss: -9.4500, Accuracy: 9557/10000 (96%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.092203\n",
      "Train Epoch: 13 [20000/60000 (33%)]\tLoss: 0.194076\n",
      "Train Epoch: 13 [40000/60000 (67%)]\tLoss: 0.168857\n",
      "\n",
      "Test set: Average loss: -10.1268, Accuracy: 9578/10000 (96%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.161564\n",
      "Train Epoch: 14 [20000/60000 (33%)]\tLoss: 0.106965\n",
      "Train Epoch: 14 [40000/60000 (67%)]\tLoss: 0.071529\n",
      "\n",
      "Test set: Average loss: -9.2636, Accuracy: 9542/10000 (95%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.304865\n",
      "Train Epoch: 15 [20000/60000 (33%)]\tLoss: 0.182202\n",
      "Train Epoch: 15 [40000/60000 (67%)]\tLoss: 0.064246\n",
      "\n",
      "Test set: Average loss: -9.9733, Accuracy: 9568/10000 (96%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.233537\n",
      "Train Epoch: 16 [20000/60000 (33%)]\tLoss: 0.019751\n",
      "Train Epoch: 16 [40000/60000 (67%)]\tLoss: 0.090512\n",
      "\n",
      "Test set: Average loss: -10.2131, Accuracy: 9513/10000 (95%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.074487\n",
      "Train Epoch: 17 [20000/60000 (33%)]\tLoss: 0.204701\n",
      "Train Epoch: 17 [40000/60000 (67%)]\tLoss: 0.113821\n",
      "\n",
      "Test set: Average loss: -10.0004, Accuracy: 9555/10000 (96%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.109280\n",
      "Train Epoch: 18 [20000/60000 (33%)]\tLoss: 0.069340\n",
      "Train Epoch: 18 [40000/60000 (67%)]\tLoss: 0.146866\n",
      "\n",
      "Test set: Average loss: -10.6277, Accuracy: 9601/10000 (96%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.028597\n",
      "Train Epoch: 19 [20000/60000 (33%)]\tLoss: 0.245842\n",
      "Train Epoch: 19 [40000/60000 (67%)]\tLoss: 0.121193\n",
      "\n",
      "Test set: Average loss: -10.5935, Accuracy: 9609/10000 (96%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.093549\n",
      "Train Epoch: 20 [20000/60000 (33%)]\tLoss: 0.075166\n",
      "Train Epoch: 20 [40000/60000 (67%)]\tLoss: 0.122376\n",
      "\n",
      "Test set: Average loss: -9.9213, Accuracy: 9579/10000 (96%)\n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.128977\n",
      "Train Epoch: 21 [20000/60000 (33%)]\tLoss: 0.030243\n",
      "Train Epoch: 21 [40000/60000 (67%)]\tLoss: 0.072854\n",
      "\n",
      "Test set: Average loss: -10.4778, Accuracy: 9613/10000 (96%)\n",
      "\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.110484\n",
      "Train Epoch: 22 [20000/60000 (33%)]\tLoss: 0.106416\n",
      "Train Epoch: 22 [40000/60000 (67%)]\tLoss: 0.192748\n",
      "\n",
      "Test set: Average loss: -10.6510, Accuracy: 9611/10000 (96%)\n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.067207\n",
      "Train Epoch: 23 [20000/60000 (33%)]\tLoss: 0.097553\n",
      "Train Epoch: 23 [40000/60000 (67%)]\tLoss: 0.188694\n",
      "\n",
      "Test set: Average loss: -9.5837, Accuracy: 9564/10000 (96%)\n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.071177\n",
      "Train Epoch: 24 [20000/60000 (33%)]\tLoss: 0.104298\n",
      "Train Epoch: 24 [40000/60000 (67%)]\tLoss: 0.030187\n",
      "\n",
      "Test set: Average loss: -10.4732, Accuracy: 9581/10000 (96%)\n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.052032\n",
      "Train Epoch: 25 [20000/60000 (33%)]\tLoss: 0.168873\n",
      "Train Epoch: 25 [40000/60000 (67%)]\tLoss: 0.183924\n",
      "\n",
      "Test set: Average loss: -10.3362, Accuracy: 9604/10000 (96%)\n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.208332\n",
      "Train Epoch: 26 [20000/60000 (33%)]\tLoss: 0.048041\n",
      "Train Epoch: 26 [40000/60000 (67%)]\tLoss: 0.171207\n",
      "\n",
      "Test set: Average loss: -10.8941, Accuracy: 9534/10000 (95%)\n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.019926\n",
      "Train Epoch: 27 [20000/60000 (33%)]\tLoss: 0.122149\n",
      "Train Epoch: 27 [40000/60000 (67%)]\tLoss: 0.133702\n",
      "\n",
      "Test set: Average loss: -10.1410, Accuracy: 9574/10000 (96%)\n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.063591\n",
      "Train Epoch: 28 [20000/60000 (33%)]\tLoss: 0.081938\n",
      "Train Epoch: 28 [40000/60000 (67%)]\tLoss: 0.169192\n",
      "\n",
      "Test set: Average loss: -9.3265, Accuracy: 9499/10000 (95%)\n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.208071\n",
      "Train Epoch: 29 [20000/60000 (33%)]\tLoss: 0.218132\n",
      "Train Epoch: 29 [40000/60000 (67%)]\tLoss: 0.090015\n",
      "\n",
      "Test set: Average loss: -10.8069, Accuracy: 9581/10000 (96%)\n",
      "\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.050363\n",
      "Train Epoch: 30 [20000/60000 (33%)]\tLoss: 0.166943\n",
      "Train Epoch: 30 [40000/60000 (67%)]\tLoss: 0.177775\n",
      "\n",
      "Test set: Average loss: -10.7418, Accuracy: 9567/10000 (96%)\n",
      "\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.080911\n",
      "Train Epoch: 31 [20000/60000 (33%)]\tLoss: 0.171348\n",
      "Train Epoch: 31 [40000/60000 (67%)]\tLoss: 0.040742\n",
      "\n",
      "Test set: Average loss: -10.1986, Accuracy: 9527/10000 (95%)\n",
      "\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.153982\n",
      "Train Epoch: 32 [20000/60000 (33%)]\tLoss: 0.153290\n",
      "Train Epoch: 32 [40000/60000 (67%)]\tLoss: 0.226828\n",
      "\n",
      "Test set: Average loss: -10.0944, Accuracy: 9592/10000 (96%)\n",
      "\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.055867\n",
      "Train Epoch: 33 [20000/60000 (33%)]\tLoss: 0.130132\n",
      "Train Epoch: 33 [40000/60000 (67%)]\tLoss: 0.073229\n",
      "\n",
      "Test set: Average loss: -9.4543, Accuracy: 9556/10000 (96%)\n",
      "\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.170167\n",
      "Train Epoch: 34 [20000/60000 (33%)]\tLoss: 0.119499\n",
      "Train Epoch: 34 [40000/60000 (67%)]\tLoss: 0.178637\n",
      "\n",
      "Test set: Average loss: -10.7919, Accuracy: 9607/10000 (96%)\n",
      "\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.051236\n",
      "Train Epoch: 35 [20000/60000 (33%)]\tLoss: 0.192455\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-e9af3eb6616e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-97ba2184a60f>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\main-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\main-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\main-env\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\main-env\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \"\"\"\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\main-env\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mnchannel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnchannel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m     \u001b[1;31m# put it from HWC to CHW format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;31m# yikes, this transpose takes 80% of the loading time/CPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "n_epochs = 100\n",
    "\n",
    "model = NetMLPLowRank(K=[8], d=[4])\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (main-env)",
   "language": "python",
   "name": "main-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
